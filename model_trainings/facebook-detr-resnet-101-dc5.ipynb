{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":105247,"databundleVersionId":13166279,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T08:24:51.964388Z","iopub.execute_input":"2025-07-26T08:24:51.964992Z","iopub.status.idle":"2025-07-26T08:24:55.908498Z","shell.execute_reply.started":"2025-07-26T08:24:51.964961Z","shell.execute_reply":"2025-07-26T08:24:55.907529Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from transformers import DetrFeatureExtractor, DetrForObjectDetection","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T08:24:59.560953Z","iopub.execute_input":"2025-07-26T08:24:59.561236Z","iopub.status.idle":"2025-07-26T08:25:25.950001Z","shell.execute_reply.started":"2025-07-26T08:24:59.561213Z","shell.execute_reply":"2025-07-26T08:25:25.949448Z"}},"outputs":[{"name":"stderr","text":"2025-07-26 08:25:09.348516: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753518309.500570      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753518309.547936      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T08:26:04.954182Z","iopub.execute_input":"2025-07-26T08:26:04.954761Z","iopub.status.idle":"2025-07-26T08:26:04.958986Z","shell.execute_reply.started":"2025-07-26T08:26:04.954727Z","shell.execute_reply":"2025-07-26T08:26:04.958128Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel_name = 'facebook/detr-resnet-101-dc5'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T08:26:06.741269Z","iopub.execute_input":"2025-07-26T08:26:06.741852Z","iopub.status.idle":"2025-07-26T08:26:06.745613Z","shell.execute_reply.started":"2025-07-26T08:26:06.741832Z","shell.execute_reply":"2025-07-26T08:26:06.744772Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"feature_extractor = DetrFeatureExtractor.from_pretrained(model_name)\nmodel = DetrForObjectDetection.from_pretrained(model_name).to(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T08:26:48.195394Z","iopub.execute_input":"2025-07-26T08:26:48.196273Z","iopub.status.idle":"2025-07-26T08:26:49.116924Z","shell.execute_reply.started":"2025-07-26T08:26:48.196240Z","shell.execute_reply":"2025-07-26T08:26:49.116138Z"}},"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import torch.nn as nn\n\nnum_classes = 3\n\nmodel.class_labels_classifier = nn.Linear(model.config.d_model, num_classes + 1)  # +1 for images without mines\nmodel.config.num_labels = num_classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T08:26:52.107190Z","iopub.execute_input":"2025-07-26T08:26:52.107468Z","iopub.status.idle":"2025-07-26T08:26:52.112829Z","shell.execute_reply.started":"2025-07-26T08:26:52.107448Z","shell.execute_reply":"2025-07-26T08:26:52.112177Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from transformers import DetrImageProcessor\n\nid2label = {\n    0: \"Explosives (All sorts of UXO, grenades, etc. that does not fall into AP/AV mine classes)\", \n    1: \"Anti-personnel mine\", \n    2: \"Anti-vehicle mine\"\n}\nlabel2id = {v: k for k, v in id2label.items()}\n\nprocessor = DetrImageProcessor.from_pretrained(model_name)\nmodel.config.id2label = id2label\nmodel.config.label2id = label2id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T08:26:55.634399Z","iopub.execute_input":"2025-07-26T08:26:55.634671Z","iopub.status.idle":"2025-07-26T08:26:55.907117Z","shell.execute_reply.started":"2025-07-26T08:26:55.634651Z","shell.execute_reply":"2025-07-26T08:26:55.906373Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def validate(model, val_dataloader):\n  model.eval()\n  running_loss = 0.0\n  for batch in val_dataloader:\n    pixel_values = batch[\"pixel_values\"].to(DEVICE)\n    pixel_mask = batch[\"pixel_mask\"].to(DEVICE)\n    labels = [{k: v.to(DEVICE) for k, v in t.items()} for t in batch[\"labels\"]]\n\n    model_output = model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\n    loss = model_output[\"loss\"]\n    running_loss += loss.item()\n  if DEVICE == \"cuda\":\n    torch.cuda.empty_cache()\n  return running_loss / len(val_dataloader)","metadata":{"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def train(model, num_epoch, train_dataloader, val_dataloader, optimizer, scheduler, device):\n  model.train()\n  for epoch in range(num_epoch):\n    for batch in train_dataloader:\n      optimizer.zero_grad()\n\n      pixel_values = batch[\"pixel_values\"].to(device)\n      pixel_mask = batch[\"pixel_mask\"].to(device)\n      labels = [{k: v.to(device) for k, v in t.items()} for t in batch[\"labels\"]]\n\n      model_output = model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\n      loss = model_output[\"loss\"]\n\n      loss.backward()\n      optimizer.step()\n    scheduler.step()\n    torch.cuda.empty_cache()\n    print(f\"Epoch: {epoch}, Training loss: {float(loss.item())}\")\n    val_loss = validate(model, val_dataloader)\n    print(f\"Epoch: {epoch}, Validation loss: {val_loss}\")\n    model.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T09:11:55.910422Z","iopub.execute_input":"2025-07-26T09:11:55.910690Z","iopub.status.idle":"2025-07-26T09:11:55.916814Z","shell.execute_reply.started":"2025-07-26T09:11:55.910670Z","shell.execute_reply":"2025-07-26T09:11:55.915972Z"}},"outputs":[],"execution_count":99},{"cell_type":"code","source":"from torch.optim.lr_scheduler import StepLR, ExponentialLR\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n# scheduler = ExponentialLR(optimizer, gamma=0.9)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T08:27:07.843259Z","iopub.execute_input":"2025-07-26T08:27:07.843910Z","iopub.status.idle":"2025-07-26T08:27:07.851444Z","shell.execute_reply.started":"2025-07-26T08:27:07.843876Z","shell.execute_reply":"2025-07-26T08:27:07.850453Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import pandas as pd\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T12:14:07.657861Z","iopub.execute_input":"2025-07-26T12:14:07.658224Z","iopub.status.idle":"2025-07-26T12:14:08.014511Z","shell.execute_reply.started":"2025-07-26T12:14:07.658198Z","shell.execute_reply":"2025-07-26T12:14:08.013295Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"folder_path = \"/kaggle/input/uadamage-demining-competition/train/annotations\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T12:14:09.778532Z","iopub.execute_input":"2025-07-26T12:14:09.778973Z","iopub.status.idle":"2025-07-26T12:14:09.783733Z","shell.execute_reply.started":"2025-07-26T12:14:09.778948Z","shell.execute_reply":"2025-07-26T12:14:09.782792Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"csv_files = [f for f in os.listdir(folder_path) if f.endswith(\".csv\")]\n\n# Read and combine them into one DataFrame\ndf_list = [pd.read_csv(os.path.join(folder_path, file)) for file in csv_files]\ncombined_df = pd.concat(df_list, ignore_index=True)\n\nprint(combined_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T12:14:11.420652Z","iopub.execute_input":"2025-07-26T12:14:11.420924Z","iopub.status.idle":"2025-07-26T12:15:01.564314Z","shell.execute_reply.started":"2025-07-26T12:14:11.420904Z","shell.execute_reply":"2025-07-26T12:15:01.563203Z"}},"outputs":[{"name":"stdout","text":"                                            image_id label     x     y width  \\\n0  0fe78fe9d92a221824bb46e63bae648dab551506f4cd5c...     0  3759  3741   133   \n1  ef87e4060b04f09fbc665c32042598b231a6d8a5e78b12...     1  2292  1805    67   \n2  1b7a46422e95fe21c97a5a7c92c2cbccb554411f80ca62...     0  3434  2032    55   \n3  b829bfb91340ab2d3af2123e4c14860451a6aa0dd8451a...     0  1594  1561    36   \n4  cb535576553cb2927691603948b420fe541ac5ff644b5b...     1  2185  1207    57   \n\n  height image_width image_height  \n0    115        5280         3956  \n1     76        4000         3000  \n2     56        3840         2160  \n3    128        3227         3226  \n4     57        4000         3000  \n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"combined_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T12:17:58.843832Z","iopub.execute_input":"2025-07-26T12:17:58.844974Z","iopub.status.idle":"2025-07-26T12:17:58.858025Z","shell.execute_reply.started":"2025-07-26T12:17:58.844930Z","shell.execute_reply":"2025-07-26T12:17:58.856566Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                            image_id label     x     y width  \\\n0  0fe78fe9d92a221824bb46e63bae648dab551506f4cd5c...     0  3759  3741   133   \n1  ef87e4060b04f09fbc665c32042598b231a6d8a5e78b12...     1  2292  1805    67   \n2  1b7a46422e95fe21c97a5a7c92c2cbccb554411f80ca62...     0  3434  2032    55   \n3  b829bfb91340ab2d3af2123e4c14860451a6aa0dd8451a...     0  1594  1561    36   \n4  cb535576553cb2927691603948b420fe541ac5ff644b5b...     1  2185  1207    57   \n\n  height image_width image_height  \n0    115        5280         3956  \n1     76        4000         3000  \n2     56        3840         2160  \n3    128        3227         3226  \n4     57        4000         3000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>label</th>\n      <th>x</th>\n      <th>y</th>\n      <th>width</th>\n      <th>height</th>\n      <th>image_width</th>\n      <th>image_height</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0fe78fe9d92a221824bb46e63bae648dab551506f4cd5c...</td>\n      <td>0</td>\n      <td>3759</td>\n      <td>3741</td>\n      <td>133</td>\n      <td>115</td>\n      <td>5280</td>\n      <td>3956</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ef87e4060b04f09fbc665c32042598b231a6d8a5e78b12...</td>\n      <td>1</td>\n      <td>2292</td>\n      <td>1805</td>\n      <td>67</td>\n      <td>76</td>\n      <td>4000</td>\n      <td>3000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1b7a46422e95fe21c97a5a7c92c2cbccb554411f80ca62...</td>\n      <td>0</td>\n      <td>3434</td>\n      <td>2032</td>\n      <td>55</td>\n      <td>56</td>\n      <td>3840</td>\n      <td>2160</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b829bfb91340ab2d3af2123e4c14860451a6aa0dd8451a...</td>\n      <td>0</td>\n      <td>1594</td>\n      <td>1561</td>\n      <td>36</td>\n      <td>128</td>\n      <td>3227</td>\n      <td>3226</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cb535576553cb2927691603948b420fe541ac5ff644b5b...</td>\n      <td>1</td>\n      <td>2185</td>\n      <td>1207</td>\n      <td>57</td>\n      <td>57</td>\n      <td>4000</td>\n      <td>3000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"image_folder = \"/kaggle/input/uadamage-demining-competition/train/images\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T08:29:00.089083Z","iopub.execute_input":"2025-07-26T08:29:00.089713Z","iopub.status.idle":"2025-07-26T08:29:00.093624Z","shell.execute_reply.started":"2025-07-26T08:29:00.089682Z","shell.execute_reply":"2025-07-26T08:29:00.092755Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T08:34:22.430729Z","iopub.execute_input":"2025-07-26T08:34:22.431409Z","iopub.status.idle":"2025-07-26T08:34:22.435029Z","shell.execute_reply.started":"2025-07-26T08:34:22.431376Z","shell.execute_reply":"2025-07-26T08:34:22.434276Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"max_image_width = combined_df['image_width'].max()\nmax_image_height = combined_df['image_height'].max()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T08:45:11.991445Z","iopub.execute_input":"2025-07-26T08:45:11.991699Z","iopub.status.idle":"2025-07-26T08:45:11.997188Z","shell.execute_reply.started":"2025-07-26T08:45:11.991682Z","shell.execute_reply":"2025-07-26T08:45:11.996435Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"max_image_width","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T08:46:22.222117Z","iopub.execute_input":"2025-07-26T08:46:22.222693Z","iopub.status.idle":"2025-07-26T08:46:22.227758Z","shell.execute_reply.started":"2025-07-26T08:46:22.222668Z","shell.execute_reply":"2025-07-26T08:46:22.226938Z"}},"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"13911"},"metadata":{}}],"execution_count":64},{"cell_type":"code","source":"max_image_height","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T08:46:27.375442Z","iopub.execute_input":"2025-07-26T08:46:27.375747Z","iopub.status.idle":"2025-07-26T08:46:27.380688Z","shell.execute_reply.started":"2025-07-26T08:46:27.375724Z","shell.execute_reply":"2025-07-26T08:46:27.379982Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"13182"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"min_image_width = combined_df['image_width'].min()\nmin_image_height = combined_df['image_height'].min()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T08:45:33.013326Z","iopub.execute_input":"2025-07-26T08:45:33.013632Z","iopub.status.idle":"2025-07-26T08:45:33.019847Z","shell.execute_reply.started":"2025-07-26T08:45:33.013612Z","shell.execute_reply":"2025-07-26T08:45:33.018903Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom PIL import Image\n\nclass CocoFormatDataset(Dataset):\n    def __init__(self, dataframe, image_folder, processor):\n        self.image_folder = image_folder\n        self.processor = processor\n        self.data = dataframe.groupby(\"image_id\")\n        self.ids = list(self.data.groups.keys())\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        image_id = self.ids[idx]\n        group = self.data.get_group(image_id)\n\n        image_path = f\"{self.image_folder}/{image_id}.jpg\"\n        image = Image.open(image_path).convert(\"RGB\")\n\n        annotations = []\n        for _, row in group.iterrows():\n            x, y, w, h = float(row[\"x\"]), float(row[\"y\"]), float(row[\"width\"]), float(row[\"height\"])\n            category_id = int(row[\"label\"])\n            annotations.append({\n                \"bbox\": [x, y, w, h],\n                \"area\": w * h,\n                \"category_id\": category_id\n            })\n\n        target = {\n            \"image_id\": idx,\n            \"annotations\": annotations\n        }\n\n        # Encode inputs\n        size = {\n            \"shortest_edge\": 640,\n            \"longest_edge\": 13911\n        }\n        encoding = self.processor(images=image, annotations=target, return_tensors=\"pt\", size={'height': 640, 'width': 640})\n        encoding = {\n            k: (v.squeeze(0) if isinstance(v, torch.Tensor) else v)\n            for k, v in encoding.items()\n        }\n        return encoding\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T08:49:56.900398Z","iopub.execute_input":"2025-07-26T08:49:56.900672Z","iopub.status.idle":"2025-07-26T08:49:56.909485Z","shell.execute_reply.started":"2025-07-26T08:49:56.900653Z","shell.execute_reply":"2025-07-26T08:49:56.908652Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"def move_label_to_device(label, device):\n    # label can be a dict or list of dicts, but here assume dict\n    if isinstance(label, list):\n        # If label is a list of dicts, move each dict\n        return [{k: v.to(device) for k, v in l.items()} for l in label]\n    else:\n        return {k: v.to(device) for k, v in label.items()}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T08:55:43.569538Z","iopub.execute_input":"2025-07-26T08:55:43.569813Z","iopub.status.idle":"2025-07-26T08:55:43.574475Z","shell.execute_reply.started":"2025-07-26T08:55:43.569794Z","shell.execute_reply":"2025-07-26T08:55:43.573812Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"from torch.utils.data import DataLoader, random_split\n\ndataset = CocoFormatDataset(combined_df, image_folder, processor)\n\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: {\n    \"pixel_values\": torch.stack([i[\"pixel_values\"] for i in x]),\n    \"pixel_mask\": torch.stack([i[\"pixel_mask\"] for i in x]),\n    \"labels\": [move_label_to_device(i[\"labels\"][0] if isinstance(i[\"labels\"], list) else i[\"labels\"], DEVICE) for i in x]\n})\nval_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: {\n    \"pixel_values\": torch.stack([i[\"pixel_values\"] for i in x]),\n    \"pixel_mask\": torch.stack([i[\"pixel_mask\"] for i in x]),\n    \"labels\": [move_label_to_device(i[\"labels\"][0] if isinstance(i[\"labels\"], list) else i[\"labels\"], DEVICE) for i in x]\n})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T09:13:12.064639Z","iopub.execute_input":"2025-07-26T09:13:12.064882Z","iopub.status.idle":"2025-07-26T09:13:12.101523Z","shell.execute_reply.started":"2025-07-26T09:13:12.064865Z","shell.execute_reply":"2025-07-26T09:13:12.100743Z"}},"outputs":[],"execution_count":102},{"cell_type":"code","source":"model.to('cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T08:57:50.763144Z","iopub.execute_input":"2025-07-26T08:57:50.763658Z","iopub.status.idle":"2025-07-26T08:57:50.775713Z","shell.execute_reply.started":"2025-07-26T08:57:50.763637Z","shell.execute_reply":"2025-07-26T08:57:50.775184Z"}},"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"DetrForObjectDetection(\n  (model): DetrModel(\n    (backbone): DetrConvModel(\n      (conv_encoder): DetrConvEncoder(\n        (model): FeatureListNet(\n          (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n          (bn1): DetrFrozenBatchNorm2d()\n          (act1): ReLU(inplace=True)\n          (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n          (layer1): Sequential(\n            (0): Bottleneck(\n              (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): DetrFrozenBatchNorm2d()\n              (act1): ReLU(inplace=True)\n              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn2): DetrFrozenBatchNorm2d()\n              (drop_block): Identity()\n              (act2): ReLU(inplace=True)\n              (aa): Identity()\n              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): DetrFrozenBatchNorm2d()\n              (act3): ReLU(inplace=True)\n              (downsample): Sequential(\n                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (1): DetrFrozenBatchNorm2d()\n              )\n            )\n            (1): Bottleneck(\n              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): DetrFrozenBatchNorm2d()\n              (act1): ReLU(inplace=True)\n              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn2): DetrFrozenBatchNorm2d()\n              (drop_block): Identity()\n              (act2): ReLU(inplace=True)\n              (aa): Identity()\n              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): DetrFrozenBatchNorm2d()\n              (act3): ReLU(inplace=True)\n            )\n            (2): Bottleneck(\n              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): DetrFrozenBatchNorm2d()\n              (act1): ReLU(inplace=True)\n              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn2): DetrFrozenBatchNorm2d()\n              (drop_block): Identity()\n              (act2): ReLU(inplace=True)\n              (aa): Identity()\n              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): DetrFrozenBatchNorm2d()\n              (act3): ReLU(inplace=True)\n            )\n          )\n          (layer2): Sequential(\n            (0): Bottleneck(\n              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): DetrFrozenBatchNorm2d()\n              (act1): ReLU(inplace=True)\n              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n              (bn2): DetrFrozenBatchNorm2d()\n              (drop_block): Identity()\n              (act2): ReLU(inplace=True)\n              (aa): Identity()\n              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): DetrFrozenBatchNorm2d()\n              (act3): ReLU(inplace=True)\n              (downsample): Sequential(\n                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n                (1): DetrFrozenBatchNorm2d()\n              )\n            )\n            (1): Bottleneck(\n              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): DetrFrozenBatchNorm2d()\n              (act1): ReLU(inplace=True)\n              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn2): DetrFrozenBatchNorm2d()\n              (drop_block): Identity()\n              (act2): ReLU(inplace=True)\n              (aa): Identity()\n              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): DetrFrozenBatchNorm2d()\n              (act3): ReLU(inplace=True)\n            )\n            (2): Bottleneck(\n              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): DetrFrozenBatchNorm2d()\n              (act1): ReLU(inplace=True)\n              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn2): DetrFrozenBatchNorm2d()\n              (drop_block): Identity()\n              (act2): ReLU(inplace=True)\n              (aa): Identity()\n              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): DetrFrozenBatchNorm2d()\n              (act3): ReLU(inplace=True)\n            )\n            (3): Bottleneck(\n              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): DetrFrozenBatchNorm2d()\n              (act1): ReLU(inplace=True)\n              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn2): DetrFrozenBatchNorm2d()\n              (drop_block): Identity()\n              (act2): ReLU(inplace=True)\n              (aa): Identity()\n              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): DetrFrozenBatchNorm2d()\n              (act3): ReLU(inplace=True)\n            )\n          )\n          (layer3): Sequential(\n            (0): Bottleneck(\n              (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): DetrFrozenBatchNorm2d()\n              (act1): ReLU(inplace=True)\n              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n              (bn2): DetrFrozenBatchNorm2d()\n              (drop_block): Identity()\n              (act2): ReLU(inplace=True)\n              (aa): Identity()\n              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): DetrFrozenBatchNorm2d()\n              (act3): ReLU(inplace=True)\n              (downsample): Sequential(\n                (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n                (1): DetrFrozenBatchNorm2d()\n              )\n            )\n            (1): Bottleneck(\n              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): DetrFrozenBatchNorm2d()\n              (act1): ReLU(inplace=True)\n              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn2): DetrFrozenBatchNorm2d()\n              (drop_block): Identity()\n              (act2): ReLU(inplace=True)\n              (aa): Identity()\n              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): DetrFrozenBatchNorm2d()\n              (act3): ReLU(inplace=True)\n            )\n            (2): Bottleneck(\n              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): DetrFrozenBatchNorm2d()\n              (act1): ReLU(inplace=True)\n              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn2): DetrFrozenBatchNorm2d()\n              (drop_block): Identity()\n              (act2): ReLU(inplace=True)\n              (aa): Identity()\n              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): DetrFrozenBatchNorm2d()\n              (act3): ReLU(inplace=True)\n            )\n            (3): Bottleneck(\n              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): DetrFrozenBatchNorm2d()\n              (act1): ReLU(inplace=True)\n              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn2): DetrFrozenBatchNorm2d()\n              (drop_block): Identity()\n              (act2): ReLU(inplace=True)\n              (aa): Identity()\n              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): DetrFrozenBatchNorm2d()\n              (act3): ReLU(inplace=True)\n            )\n            (4): Bottleneck(\n              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): DetrFrozenBatchNorm2d()\n              (act1): ReLU(inplace=True)\n              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn2): DetrFrozenBatchNorm2d()\n              (drop_block): Identity()\n              (act2): ReLU(inplace=True)\n              (aa): Identity()\n              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): DetrFrozenBatchNorm2d()\n              (act3): ReLU(inplace=True)\n            )\n            (5): Bottleneck(\n              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): DetrFrozenBatchNorm2d()\n              (act1): ReLU(inplace=True)\n              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn2): DetrFrozenBatchNorm2d()\n              (drop_block): Identity()\n              (act2): ReLU(inplace=True)\n              (aa): Identity()\n              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): DetrFrozenBatchNorm2d()\n              (act3): ReLU(inplace=True)\n            )\n          )\n          (layer4): Sequential(\n            (0): Bottleneck(\n              (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): DetrFrozenBatchNorm2d()\n              (act1): ReLU(inplace=True)\n              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n              (bn2): DetrFrozenBatchNorm2d()\n              (drop_block): Identity()\n              (act2): ReLU(inplace=True)\n              (aa): Identity()\n              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): DetrFrozenBatchNorm2d()\n              (act3): ReLU(inplace=True)\n              (downsample): Sequential(\n                (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n                (1): DetrFrozenBatchNorm2d()\n              )\n            )\n            (1): Bottleneck(\n              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): DetrFrozenBatchNorm2d()\n              (act1): ReLU(inplace=True)\n              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn2): DetrFrozenBatchNorm2d()\n              (drop_block): Identity()\n              (act2): ReLU(inplace=True)\n              (aa): Identity()\n              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): DetrFrozenBatchNorm2d()\n              (act3): ReLU(inplace=True)\n            )\n            (2): Bottleneck(\n              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn1): DetrFrozenBatchNorm2d()\n              (act1): ReLU(inplace=True)\n              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn2): DetrFrozenBatchNorm2d()\n              (drop_block): Identity()\n              (act2): ReLU(inplace=True)\n              (aa): Identity()\n              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn3): DetrFrozenBatchNorm2d()\n              (act3): ReLU(inplace=True)\n            )\n          )\n        )\n      )\n      (position_embedding): DetrSinePositionEmbedding()\n    )\n    (input_projection): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n    (query_position_embeddings): Embedding(100, 256)\n    (encoder): DetrEncoder(\n      (layers): ModuleList(\n        (0-5): 6 x DetrEncoderLayer(\n          (self_attn): DetrAttention(\n            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): ReLU()\n          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (decoder): DetrDecoder(\n      (layers): ModuleList(\n        (0-5): 6 x DetrDecoderLayer(\n          (self_attn): DetrAttention(\n            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n          )\n          (activation_fn): ReLU()\n          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): DetrAttention(\n            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (class_labels_classifier): Linear(in_features=256, out_features=4, bias=True)\n  (bbox_predictor): DetrMLPPredictionHead(\n    (layers): ModuleList(\n      (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n      (2): Linear(in_features=256, out_features=4, bias=True)\n    )\n  )\n)"},"metadata":{}}],"execution_count":96},{"cell_type":"code","source":"num_epoches = 1\n\ntrain(model, num_epoch=num_epoches, train_dataloader=train_loader, val_dataloader=val_loader, optimizer=optimizer, scheduler=scheduler, device=DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T08:57:56.523483Z","iopub.execute_input":"2025-07-26T08:57:56.524127Z","iopub.status.idle":"2025-07-26T09:10:43.744247Z","shell.execute_reply.started":"2025-07-26T08:57:56.524074Z","shell.execute_reply":"2025-07-26T09:10:43.743257Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (144000168 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (165888675 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Training loss: 4.455962657928467\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3463579521.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epoches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epoches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/2993986496.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, num_epoch, train_dataloader, val_dataloader, optimizer, scheduler, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch: {epoch}, Training loss: {float(loss.item())}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch: {epoch}, Validation loss: {val_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: validate() takes 2 positional arguments but 3 were given"],"ename":"TypeError","evalue":"validate() takes 2 positional arguments but 3 were given","output_type":"error"}],"execution_count":97},{"cell_type":"code","source":"num_epoches = 5\n\ntrain(model, num_epoch=num_epoches, train_dataloader=train_loader, val_dataloader=val_loader, optimizer=optimizer, scheduler=scheduler, device=DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T09:13:18.093283Z","iopub.execute_input":"2025-07-26T09:13:18.093572Z","iopub.status.idle":"2025-07-26T10:29:18.843853Z","shell.execute_reply.started":"2025-07-26T09:13:18.093550Z","shell.execute_reply":"2025-07-26T10:29:18.842849Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (144000168 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (165888675 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Training loss: 3.6609911918640137\nEpoch: 0, Validation loss: 3.8208777886028438\nEpoch: 1, Training loss: 3.4690310955047607\nEpoch: 1, Validation loss: 3.6939996711967527\nEpoch: 2, Training loss: 3.6269371509552\nEpoch: 2, Validation loss: 4.119842100513074\nEpoch: 3, Training loss: 4.2913103103637695\nEpoch: 3, Validation loss: 5.0156597333361015\nEpoch: 4, Training loss: 3.8866004943847656\nEpoch: 4, Validation loss: 3.694206962289736\n","output_type":"stream"}],"execution_count":103},{"cell_type":"code","source":"num_epoches = 5\n\ntrain(model, num_epoch=num_epoches, train_dataloader=train_loader, val_dataloader=val_loader, optimizer=optimizer, scheduler=scheduler, device=DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T10:32:04.122646Z","iopub.execute_input":"2025-07-26T10:32:04.123132Z","iopub.status.idle":"2025-07-26T10:49:58.800387Z","shell.execute_reply.started":"2025-07-26T10:32:04.123082Z","shell.execute_reply":"2025-07-26T10:49:58.799393Z"}},"outputs":[{"name":"stdout","text":"Epoch: 0, Training loss: 3.7004446983337402\nEpoch: 0, Validation loss: 3.800423446551774\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2239771924.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epoches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epoches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/4162578015.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, num_epoch, train_dataloader, val_dataloader, optimizer, scheduler, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixel_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpixel_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/detr/modeling_detr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values, pixel_mask, decoder_attention_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;31m# First, sent images through DETR base model to obtain encoder + decoder outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1393\u001b[0m             \u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0mpixel_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpixel_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/detr/modeling_detr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values, pixel_mask, decoder_attention_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0;31m# flattened_mask is a Tensor of shape (batch_size, height*width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoder_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m             encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1232\u001b[0m                 \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflattened_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflattened_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/detr/modeling_detr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs_embeds, attention_mask, object_queries, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;31m# we add object_queries as extra input to the encoder_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                 layer_outputs = encoder_layer(\n\u001b[0m\u001b[1;32m    909\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/detr/modeling_detr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, object_queries, output_attentions)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m                 \u001b[0mclamp_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mclamp_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclamp_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":104},{"cell_type":"code","source":"num_epoches = 10\n\ntrain(model, num_epoch=num_epoches, train_dataloader=train_loader, val_dataloader=val_loader, optimizer=optimizer, scheduler=scheduler, device=DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T10:50:22.451779Z","iopub.execute_input":"2025-07-26T10:50:22.452060Z","execution_failed":"2025-07-26T11:45:32.804Z"}},"outputs":[{"name":"stdout","text":"Epoch: 0, Training loss: 3.6952943801879883\nEpoch: 0, Validation loss: 6.474891093350196\nEpoch: 1, Training loss: 3.6181132793426514\nEpoch: 1, Validation loss: 7.253440162008123\nEpoch: 2, Training loss: 3.660289764404297\nEpoch: 2, Validation loss: 8.138101078743158\n","output_type":"stream"}],"execution_count":null}]}